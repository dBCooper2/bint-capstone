---
title: NBA Hypothesis Testing - Home vs Away Analysis
description: Hypothesis tests examining data differences in Home vs Away Data from 2004-2024
date: 2025-02-24
tags: ["basketball","data-analysis","python"]
published: true
---

This notebook covers data transformation, data visualization, and hypothesis testing of NBA game data from 2004 to 2024. The goal of this analysis is to see if there is a meaningful difference in a team playing at home vs on the road.

## 1. Importing Packages and Data

This analysis uses `numpy`, `pandas`, `scipy`, `statsmodels`, `matplotlib`, `seaborn`, and `missingno`.

Here is a quick summary of the data, which was accessed from swar's [nba_api](<https://github.com/swar/nba_api) package.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>game_id</th>
      <th>season</th>
      <th>team_id</th>
      <th>team_name</th>
      <th>tri_code</th>
      <th>team_slug</th>
      <th>minutes</th>
      <th>field_goals_made</th>
      <th>field_goals_attempted</th>
      <th>field_goals_percentage</th>
      <th>...</th>
      <th>uncontested_field_goals_percentage</th>
      <th>field_goal_percentage</th>
      <th>defended_at_rim_field_goals_made</th>
      <th>defended_at_rim_field_goals_attempted</th>
      <th>defended_at_rim_field_goal_percentage</th>
      <th>opponent_points</th>
      <th>is_home_team</th>
      <th>won_game</th>
      <th>is_playoff_game</th>
      <th>is_regular_game</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>40400407</td>
      <td>2004-05</td>
      <td>1610612759</td>
      <td>Spurs</td>
      <td>SAS</td>
      <td>spurs</td>
      <td>240:00</td>
      <td>29.0</td>
      <td>68.0</td>
      <td>0.426</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.426</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>74.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>40400406</td>
      <td>2004-05</td>
      <td>1610612759</td>
      <td>Spurs</td>
      <td>SAS</td>
      <td>spurs</td>
      <td>240:00</td>
      <td>31.0</td>
      <td>75.0</td>
      <td>0.413</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.413</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>95.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40400405</td>
      <td>2004-05</td>
      <td>1610612765</td>
      <td>Pistons</td>
      <td>DET</td>
      <td>pistons</td>
      <td>265:00</td>
      <td>37.0</td>
      <td>84.0</td>
      <td>0.440</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.440</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>96.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>40400404</td>
      <td>2004-05</td>
      <td>1610612765</td>
      <td>Pistons</td>
      <td>DET</td>
      <td>pistons</td>
      <td>240:00</td>
      <td>41.0</td>
      <td>90.0</td>
      <td>0.456</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.456</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>71.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>40400403</td>
      <td>2004-05</td>
      <td>1610612765</td>
      <td>Pistons</td>
      <td>DET</td>
      <td>pistons</td>
      <td>240:00</td>
      <td>40.0</td>
      <td>85.0</td>
      <td>0.471</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.471</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>79.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>40400402</td>
      <td>2004-05</td>
      <td>1610612759</td>
      <td>Spurs</td>
      <td>SAS</td>
      <td>spurs</td>
      <td>240:00</td>
      <td>29.0</td>
      <td>62.0</td>
      <td>0.468</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.468</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>76.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>40400401</td>
      <td>2004-05</td>
      <td>1610612759</td>
      <td>Spurs</td>
      <td>SAS</td>
      <td>spurs</td>
      <td>240:00</td>
      <td>34.0</td>
      <td>79.0</td>
      <td>0.430</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.430</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>69.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>40400307</td>
      <td>2004-05</td>
      <td>1610612748</td>
      <td>Heat</td>
      <td>MIA</td>
      <td>heat</td>
      <td>240:00</td>
      <td>32.0</td>
      <td>69.0</td>
      <td>0.464</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.464</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>88.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>40400306</td>
      <td>2004-05</td>
      <td>1610612765</td>
      <td>Pistons</td>
      <td>DET</td>
      <td>pistons</td>
      <td>240:00</td>
      <td>36.0</td>
      <td>86.0</td>
      <td>0.419</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.419</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>66.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>40400305</td>
      <td>2004-05</td>
      <td>1610612748</td>
      <td>Heat</td>
      <td>MIA</td>
      <td>heat</td>
      <td>240:00</td>
      <td>36.0</td>
      <td>69.0</td>
      <td>0.522</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.522</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>76.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>10 rows Ã— 72 columns</p>
</div>

After cleaning the data, win percentages from home and away games can be examined.

## 2. Examining Win Percentages for Teams

### 2.a. Calculating Win Percentages

To examine the win percentages of home and away games, we need to group the dataset by season, then we can create the win percentage for home games by finding the mean of the win counts for home and away games.

```python
# Adding Win Percentages
win_percent = (
    df_sac[df_sac["is_home_team"] == 1]  # Filter for home games
    .groupby("season")["won_game"]       # Group by season, selecting only won_game
    .mean()                              # Compute win percentage
    .reset_index()                       # Convert back to DataFrame
)

win_percent.rename(columns={"won_game": "home_win_pct"}, inplace=True)

# Let's also add away win pct in case we do a stacked bar chart
win_percent['away_win_pct'] = 1 - win_percent['home_win_pct']
win_percent
```

From the data, we can see that the home win percentage (`home_win_pct`) is, on average, decreasing each season. Let's take a look at some visualizations of this data, then dive into factors to try to explain why this is happening.

## 2.b. Visualizations of Win Percentages Over Time

Now that we have the home and away win percentages over time, let's create some visualizations to see what is happening with win rates.

```python
fig, ax = plt.subplots(figsize=(24, 12))

ax.bar(win_percent['season'], win_percent['home_win_pct'], label='Home Win %', color='#1f77b4')
ax.bar(win_percent['season'], win_percent['away_win_pct'], 
       bottom=win_percent['home_win_pct'], label='Away Win %', color='#ff7f0e')

ax.set_ylabel('Win Percentage')
ax.set_xlabel('Season')
ax.set_title('Home and Away Win Percentages by Season')
ax.legend()

plt.show()
```

Which results in the following image:

![Home vs Away Win Percentages Aggregated by Season](public/articles/2024-2-24/home-vs-away-win-pct.png)

This chart muddies the waters a bit. From the DataFrame, we do see a very slight downward trend in the win percentages at home, but the chart has a more uniform distribution. However,  in Michael MacKelvie's video on Home vs. Away Games, home win percentages are going down over a larger time horizon. Home win % is highest as far back as the 1940's, then decreases until a local maximum in the 1980's, then goes back to decreasing again.

We will need to expand our time horizon to confirm there is a more dramatic trend, but for now lets take that slight downward trend and run with it, examining the factors **why** that percent might be going down.

## 3. Factors to Examine

So what is causing this decline that we can examine in our data? We can examine the statistics in our dataset like free throws, 3 pointers, turnovers, and defensive/offensive rebounds to see if the group means and variances between home and away games are the same. If the means are the same, we can intuit that the statistic does not have a meaningful impact on home win percentage. If the means or variances are not the same, then we can infer that they have a meaningful impact on a teams win percentage at home or away.

### 3.a. Splitting DataFrames into Home and Away Games

First we need to create 2 DataFrames, 1 for Home and 1 for Away games.

```python
home_df = cleaned[cleaned['is_home_team']==1]
away_df = cleaned[cleaned['is_home_team']==0]
```

Lastly, we will filter down the DataFrames into just the columns we wish to examine.

```python
cols_of_interest = ['game_id',
                    'season',
                    'tri_code',
                    'field_goals_percentage',
                    'three_pointers_percentage',
                    'free_throws_percentage',
                    'rebounds_offensive',
                    'rebounds_defensive',
                    'contested_field_goal_percentage',
                    'uncontested_field_goals_percentage',
                    ]

home_df_filtered = home_df[cols_of_interest]
away_df_filtered = away_df[cols_of_interest]
```

Let's break the data down further into `pandas.Series` objects to pass into the plotting and statistical testing functions we will define in the next section.

```python
# Field Goal Percentage
home_fg_pct = home_df['field_goal_percentage']
away_fg_pct = away_df['field_goal_percentage']
l_fg = [home_fg_pct, away_fg_pct]

# Three-Pointer Percentage
home_tp_pct = home_df['three_pointers_percentage']
away_tp_pct = away_df['three_pointers_percentage']
l_tp = [home_tp_pct, away_tp_pct]

# Free-Throw Percentage
home_ft_pct = home_df['free_throws_percentage']
away_ft_pct = away_df['free_throws_percentage']
l_ft = [home_ft_pct, away_ft_pct]

# Offensive Rebounds
home_r_off = home_df['rebounds_offensive']
away_r_off = away_df['rebounds_offensive']
l_r_off = [home_r_off, away_r_off]

# Defensive Rebounds
home_r_def = home_df['rebounds_defensive']
away_r_def = away_df['rebounds_defensive']
l_r_def = [home_r_def, away_r_def]

# Contested Field Goals
home_cfg_pct = home_df['contested_field_goal_percentage']
away_cfg_pct = away_df['contested_field_goal_percentage']
l_cfg = [home_cfg_pct, away_cfg_pct]

# Uncontested Field Goals
home_ufg_pct = home_df['uncontested_field_goals_percentage']
away_ufg_pct = away_df['uncontested_field_goals_percentage']
l_ufg = [home_ufg_pct, away_ufg_pct]
```

## 4. Normality Testing

Now that we have cleaned home and away game DataFrames, we can begin to create hypothesis tests. The following sections will examine the distributions to test for normality, to determine whether we need to use parametric or non-parametric tests.

### 4.a. Examining Distributions

We will construct Histograms and QQ Plots of each variable of interest in this section. The following cells will define functions to plot these charts, and break the dataframe into lists of data to chart in the histograms.

```python
def side_by_side_hists(l:list, titles:list):
    # Create a figure and axis objects
    fig, axs = plt.subplots(1, 2, figsize=(25, 10))

    # Loop through the subplots and add the histograms
    sns.histplot(data=l[0].dropna(), ax=axs[0], bins=50, kde=True, color='#2142ab')
    sns.histplot(data=l[1].dropna(), ax=axs[1], bins=50, kde=True, color='#2142ab')

    # Assign Titles
    axs[0].set_title(f'{titles[0]} - 2004-2024')
    axs[1].set_title(f'{titles[1]} - 2004-2024')

    # Adjust layout
    plt.tight_layout()

    # Show plot
    plt.show()
    return
```

```python
def side_by_side_qq_plots(l:list, titles:list):
    # Generate a Normal Distribution for the QQ Plots
    mean = 0  # Normal Dists are mean=0, stddev=1
    std_dev = 1
    size = 100  # len of arr
    normal_data = np.random.normal(loc=mean, scale=std_dev, size=size)
    normal_series = pd.Series(normal_data) # convert to series to match format

    # Set up the panel
    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(40,10), squeeze=False)

    # Add titles
    axs[0][0].set_title(f'Normal Dist. vs. {titles[0]} - 2004-2024')
    axs[0][1].set_title(f'Normal Dist. vs. {titles[1]} - 2004-2024')
    axs[0][2].set_title('Normal Dist. vs. Normal Dist.')

    # Plot Data
    sm.qqplot(l[0],dist=stats.norm,ax=axs[0][0],line='45')
    sm.qqplot(l[1],dist=stats.norm,ax=axs[0][1],line='45')
    sm.qqplot(normal_series,dist=stats.norm,ax=axs[0][2],line='45')

    plt.show()
```

Visualizations are not enough to confirm the data is normally distributed though. To confirm the results of the charts, we will define functions to run the **Shapiro-Wilk** test of Normality, the **Anderson-Darling** test, which tests if a sample is from a given probablity distribution. Both tests are needed due to the large sample size of the data, after $N > 5000$ the Shapiro-Wilk test may provide an inaccurate p-value.

##### Shapiro-Wilk Test

The Shapiro-Wilk Test of Normality is defined as:

$$
\begin{align*}
H_0 &\text{: The data has been sampled from a normal distribution, } N(\mu,\sigma^2) \\
H_1 &\text{: The data has has not been sampled from a normal distribution, } N(\mu,\sigma^2)
\end{align*}
$$

The test is run by computing a test statistic, $W$, and returns a $p$-value for us to interpret. From this test, a $p$-value below the significance level tells us to reject the null hypothesis $H_0$, and *we cannot assume Normality*.

We are using `scipy.stats`'s `shapiro` function to run this test, then the function will print the results in a more readable format.

```python
def run_shapiro_test(l:list):
    from scipy.stats import shapiro
    w_home = shapiro(l[0])
    w_away = shapiro(l[1])

    print(f'Home Games:\n  Test Stat (W): {w_home.statistic},\n  p-value: {w_home.pvalue}\n')
    print(f'Away Games:\n  Test Stat (W): {w_away.statistic},\n  p-value: {w_away.pvalue}\n')

    return w_home, w_away
```

##### Anderson-Darling Test

The Shapiro-Wilk Test is useful for determining normality of a sample, but has one fatal flaw: *it produces inaccurate p-values for* $N > 5000$. This means another test, the Anderson-Darling (AD) Test, must be used. The Anderson-Darling Test is as follows:

$$
\begin{align*}
H_0&\text{: The data comes from the chosen (normal) distribution} \\
H_1&\text{: The data does not come from the chosen (normal) distribution} \\
\end{align*}
$$

AD Testing checks if a sample comes from a provided distribution. Meaning, we can provide a sample to it along with a desired distribution to test (The normal distribution $N$ in our case), and get a result of whether our sample comes from the desired distribution or not.

We are again using `scipy.stats` for this test, using the `anderson` function. The function returns the test statistic, an array of critical values and an array of significance levels. *If the returned test statistic is larger than the critical values for the corresponding significance levels, then the null hypothesis should be rejected.*

```python
def run_ad_test(l:list):
    from scipy.stats import anderson
    home = anderson(l[0],dist='norm')
    away = anderson(l[1],dist='norm')

    print(f'Home Games:\n  Test Statistic: {home.statistic},\n  Critical Values: {home.critical_values},\n  Significance Level: {home.significance_level}\n')
    print(f'Home Games:\n  Test Statistic: {away.statistic},\n  Critical Values: {away.critical_values},\n  Significance Level: {away.significance_level}\n')

    return home, away
```

Now we can construct the Histograms, KDE's, and QQ Plots for each feature. We will store the results in a list and construct a dataframe with them later.

#### 4.a.i. Field Goal Percentage

```python
side_by_side_hists(l_fg, ['Home Field Goal Percentage', 'Away Field Goal Percentage'])
side_by_side_qq_plots(l_fg, ['Home Field Goal Percentage', 'Away Field Goal Percentage'])
```

![Home vs Away Field Goal Percentage Histogram](/path)

![Home vs Away Field Goal Percentage QQ Plots](/path)

```python
print('Shapiro-Wilks:')
run_shapiro_test(l_fg)
print('Anderson-Darling:')
run_ad_test(l_fg)
```

The Shapiro-Wilks and Anderson-Darling tests also confirm this. For Home Games we reject the Null Hypothesis for both the Shapiro-Wilks and the Anderson-Darling Tests, and we reject the Null Hypotheses for Away Games too. **This means neither home nor away games are normally distributed, and non-parametric hypothesis tests must be used.**

Because we have so many features to get through, the following sections will simply say if data looks normally distributed, and whether we accept/reject the null of each test.

#### 4.a.ii. Three Pointer Percentage

```python
side_by_side_hists(l_fg, ['Home Three Pointer Percentage', 'Away Three Pointer Percentage'])
side_by_side_qq_plots(l_fg, ['Home Three Pointer Percentage', 'Away Three Pointer Percentage'])
```

![Home vs Away Three Pointer Percentage Histogram](/path)

![Home vs Away Three Pointer Percentage QQ Plots](/path)

```python
print('Shapiro-Wilks:')
run_shapiro_test(l_fg)
print('Anderson-Darling:')
run_ad_test(l_fg)
```


