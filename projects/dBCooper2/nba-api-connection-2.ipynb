{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Data Analysis :: API Connection Part 2\n",
    "\n",
    "## Trevor Rowland :: 2-5-2025\n",
    "\n",
    "This notebook aims to collect all teams that made the playoffs in the 2004-2024 seasons, and also a Play-by-Play data grabber to use for later projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collecting Playoff Teams\n",
    "\n",
    "This function uses the PlayoffPicture endpoint from `nba_api` to get a glimpse of the playoffs in each season. This glimpse contains all of the teams who made the playoffs, which will be used in our 4th hypothesis test using MANOVA to compare playoff teams to non-playoff-making teams.\n",
    "\n",
    "**Edit:** We are no longer using the `nba_api` endpoints because that is stupid overengineering. Instead, we can just write down every playoff team from wikipedia instead of wrestling with the API.\n",
    "\n",
    "**Edit 2:** Even Better! All `game_id` values contain whether the game is a playoff game or not.\n",
    "\n",
    "Playoff Games will start off with the numbers 00...\n",
    "\n",
    "- 1: Pre-Season Games\n",
    "- 2: Regular Season Games\n",
    "- 3: All-Star Games\n",
    "- 4: Playoff Games\n",
    "\n",
    "**[Source](<https://github.com/swar/nba_api/issues/220>)**\n",
    "\n",
    "This means that we are still waiting to get the game data but at least we have an elegant solution when we get those `game_id` datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a. Playoff Teams\n",
    "\n",
    "The following is a dictionary of each playoff team that made the NBA playoffs since 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import LeagueGameFinder, BoxScoreTraditionalV2\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import random\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler('nba_data_collection.log'),\n",
    "             logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log_message(message):\n",
    "    \"\"\"Log message to both file and tqdm\"\"\"\n",
    "    tqdm.write(message)\n",
    "    logger.info(message)\n",
    "\n",
    "def exponential_backoff(attempt, base_delay=2, max_delay=60):\n",
    "    \"\"\"Calculate exponential backoff time with jitter\"\"\"\n",
    "    delay = min(base_delay * (2 ** attempt) + random.uniform(0, 1), max_delay)\n",
    "    return delay\n",
    "\n",
    "def get_season_games(season):\n",
    "    \"\"\"Get games for a single season with error handling\"\"\"\n",
    "    game_finder = LeagueGameFinder(\n",
    "        season_nullable=season,\n",
    "        league_id_nullable='00',\n",
    "        timeout=60\n",
    "    )\n",
    "    \n",
    "    # Get the raw response first\n",
    "    response_frames = game_finder.get_data_frames()\n",
    "    \n",
    "    # Debug logging\n",
    "    log_message(f\"Response for season {season}: got {len(response_frames)} DataFrames\")\n",
    "    if not response_frames:\n",
    "        raise ValueError(f\"Empty response for season {season}\")\n",
    "    \n",
    "    games = response_frames[0]\n",
    "    if len(games) == 0:\n",
    "        raise ValueError(f\"No games found for season {season}\")\n",
    "        \n",
    "    log_message(f\"Retrieved {len(games)} game entries for season {season}\")\n",
    "    return games\n",
    "\n",
    "def parse_matchup(matchup):\n",
    "    \"\"\"\n",
    "    Parse the matchup string to determine home and away teams.\n",
    "    Example formats:\n",
    "    - \"GSW vs. LAL\" -> GSW is home\n",
    "    - \"GSW @ LAL\" -> GSW is away\n",
    "    \"\"\"\n",
    "    if ' vs.' in matchup:\n",
    "        return 'home'\n",
    "    elif ' @' in matchup:\n",
    "        return 'away'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_all_game_ids(start_year, end_year):\n",
    "    \"\"\"\n",
    "    First phase: Collect all game IDs for the specified year range\n",
    "    \"\"\"\n",
    "    all_games = []\n",
    "    seasons = [f\"{year}-{str(year + 1)[-2:]}\" for year in range(start_year, end_year)]\n",
    "    \n",
    "    # Season progress bar\n",
    "    with tqdm(seasons, desc=\"Collecting game IDs\") as season_pbar:\n",
    "        for season in season_pbar:\n",
    "            season_pbar.set_description(f\"Getting games for {season}\")\n",
    "            \n",
    "            try:\n",
    "                games = get_season_games(season)\n",
    "                \n",
    "                # Debug log the structure of the data\n",
    "                log_message(f\"Processing {len(games)} game entries for {season}\")\n",
    "                \n",
    "                # Create a dictionary to store games temporarily\n",
    "                season_games_dict = {}\n",
    "                \n",
    "                # First pass: organize games by GAME_ID\n",
    "                for _, game in games.iterrows():\n",
    "                    game_id = game['GAME_ID']\n",
    "                    game_location = parse_matchup(game['MATCHUP'])\n",
    "                    \n",
    "                    if game_id not in season_games_dict:\n",
    "                        season_games_dict[game_id] = {'home': None, 'away': None}\n",
    "                    \n",
    "                    if game_location == 'home':\n",
    "                        season_games_dict[game_id]['home'] = game\n",
    "                    elif game_location == 'away':\n",
    "                        season_games_dict[game_id]['away'] = game\n",
    "                \n",
    "                # Second pass: create game records\n",
    "                games_processed = 0\n",
    "                games_skipped = 0\n",
    "                \n",
    "                for game_id, game_data in season_games_dict.items():\n",
    "                    if game_data['home'] is not None and game_data['away'] is not None:\n",
    "                        home_game = game_data['home']\n",
    "                        away_game = game_data['away']\n",
    "                        \n",
    "                        game_info = {\n",
    "                            'GAME_ID': game_id,\n",
    "                            'GAME_DATE': home_game['GAME_DATE'],\n",
    "                            'SEASON': season,\n",
    "                            'HOME_TEAM_ID': home_game['TEAM_ID'],\n",
    "                            'HOME_TEAM_NAME': home_game['TEAM_NAME'],\n",
    "                            'AWAY_TEAM_ID': away_game['TEAM_ID'],\n",
    "                            'AWAY_TEAM_NAME': away_game['TEAM_NAME'],\n",
    "                            'HOME_TEAM_SCORE': home_game['PTS'],\n",
    "                            'AWAY_TEAM_SCORE': away_game['PTS'],\n",
    "                            'GAME_TYPE': 'Playoff' if game_id.startswith('004') else 'Regular'\n",
    "                        }\n",
    "                        all_games.append(game_info)\n",
    "                        games_processed += 1\n",
    "                    else:\n",
    "                        games_skipped += 1\n",
    "                        log_message(f\"Skipping game {game_id} - Missing {'home' if game_data['home'] is None else 'away'} team data\")\n",
    "                \n",
    "                log_message(f\"Season {season} summary:\"\n",
    "                          f\"\\n - Total games found: {len(season_games_dict)}\"\n",
    "                          f\"\\n - Successfully processed: {games_processed}\"\n",
    "                          f\"\\n - Skipped: {games_skipped}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                log_message(f\"Error processing season {season}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            time.sleep(1)  # Brief pause between seasons\n",
    "    \n",
    "    if not all_games:\n",
    "        raise ValueError(\"No games collected for any season\")\n",
    "    \n",
    "    games_df = pd.DataFrame(all_games)\n",
    "    log_message(f\"Total games collected across all seasons: {len(games_df)}\")\n",
    "    return games_df\n",
    "\n",
    "def get_box_score(game_id, retries=2):\n",
    "    \"\"\"Get box score for a single game with retry logic\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            box_score = BoxScoreTraditionalV2(game_id=game_id, timeout=60)\n",
    "            response_frames = box_score.get_data_frames()\n",
    "            \n",
    "            if not response_frames:\n",
    "                raise ValueError(\"Empty response\")\n",
    "                \n",
    "            return response_frames[0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == retries - 1:  # Last attempt\n",
    "                log_message(f\"Failed to get box score for game {game_id}: {str(e)}\")\n",
    "                return None\n",
    "            delay = exponential_backoff(attempt)\n",
    "            log_message(f\"Attempt {attempt + 1} failed for game {game_id}, retrying in {delay:.1f}s\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "def collect_nba_game_data(start_year=2004, end_year=2024):\n",
    "    \"\"\"\n",
    "    Collect game-level data and box scores for NBA games between specified years.\n",
    "    \"\"\"\n",
    "    log_message(f\"Starting data collection for seasons {start_year}-{end_year}\")\n",
    "    \n",
    "    try:\n",
    "        # Phase 1: Get all game IDs and basic game info\n",
    "        games_df = get_all_game_ids(start_year, end_year)\n",
    "        log_message(f\"Found {len(games_df)} total games\")\n",
    "        \n",
    "        # Phase 2: Get box scores for each game\n",
    "        all_box_scores = []\n",
    "        successful_games = 0\n",
    "        failed_games = 0\n",
    "        \n",
    "        # Process each game\n",
    "        with tqdm(total=len(games_df), desc=\"Collecting box scores\") as pbar:\n",
    "            for _, game in games_df.iterrows():\n",
    "                game_id = game['GAME_ID']\n",
    "                \n",
    "                # Get box score\n",
    "                box_score_df = get_box_score(game_id)\n",
    "                \n",
    "                if box_score_df is not None:\n",
    "                    # Add game information to box score\n",
    "                    for col, value in game.items():\n",
    "                        box_score_df[col] = value\n",
    "                    \n",
    "                    all_box_scores.append(box_score_df)\n",
    "                    successful_games += 1\n",
    "\n",
    "                    # Write what you've got to PKL every 10 inputs\n",
    "                    if successful_games % 10==0:\n",
    "                        current_games = pd.concat(all_box_scores)\n",
    "                        current_games.to_pickle('/home/arch-db/Documents/github/bint-capstone/data-sources/OneDrive_1_2-5-2025/all-games.pkl')\n",
    "                else:\n",
    "                    failed_games += 1\n",
    "                \n",
    "                # Update progress bar with success rate\n",
    "                success_rate = (successful_games / (successful_games + failed_games)) * 100\n",
    "                pbar.set_description(\n",
    "                    f\"Box scores (Success: {successful_games}, Failed: {failed_games}, \"\n",
    "                    f\"Rate: {success_rate:.1f}%)\"\n",
    "                )\n",
    "                pbar.update(1)\n",
    "                \n",
    "                time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        # Combine box scores\n",
    "        if all_box_scores:\n",
    "            box_scores_df = pd.concat(all_box_scores, ignore_index=True)\n",
    "        else:\n",
    "            box_scores_df = pd.DataFrame()\n",
    "        \n",
    "        # Final summary\n",
    "        log_message(f\"\\nData collection completed:\"\n",
    "                    f\"\\nTotal games found: {len(games_df)}\"\n",
    "                    f\"\\nSuccessful box scores: {successful_games}\"\n",
    "                    f\"\\nFailed box scores: {failed_games}\"\n",
    "                    f\"\\nSuccess rate: {(successful_games / (successful_games + failed_games)) * 100:.1f}%\")\n",
    "        \n",
    "        return games_df, box_scores_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Critical error in data collection: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def save_data(games_df, box_scores_df, base_filename='nba_data'):\n",
    "    \"\"\"Save the collected data to CSV files with timestamps.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    games_df.to_csv(f'{base_filename}_games_{timestamp}.csv', index=False)\n",
    "    box_scores_df.to_csv(f'{base_filename}_box_scores_{timestamp}.csv', index=False)\n",
    "    log_message(f\"Data saved to {base_filename}_games_{timestamp}.csv and {base_filename}_box_scores_{timestamp}.csv\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    games_df, box_scores_df = collect_nba_game_data(2004, 2024)\n",
    "    save_data(games_df, box_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
